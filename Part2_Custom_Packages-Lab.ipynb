{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3574639f-3c11-4557-b14b-b5ecb18470f7",
   "metadata": {},
   "source": [
    "# 2. Importing Packages That Aren't In Snowflake's Anaconda Channel\n",
    "\n",
    "Now we're going to create and backtest a strategy within Snowpark using our initial data and the ML prediction.\n",
    "\n",
    "In this lab you will learn how to:\n",
    "\n",
    "1. Create a session for Snowpark with Snowflake\n",
    "2. Create a SPROC in Snowflake, and include packages that aren't in Snowflake's Anaconda Channel yet\n",
    "3. Migrate the SPROC to a vectorised UDTF functionality for better scalability\n",
    "\n",
    "## Prerequisites:\n",
    "Part 1. is assumed to have been fully executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b0536b-92e5-43c3-8ea5-e1b8efdcb621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harry/.conda/envs/snowpark-ml-hol/lib/python3.11/site-packages/backtesting/_plotting.py:50: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support (e.g. PyCharm, Spyder IDE). Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
      "  warnings.warn('Jupyter Notebook detected. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"d49cd4a6-7527-4341-8fbf-1a5403e07e2f\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"d49cd4a6-7527-4341-8fbf-1a5403e07e2f\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"d49cd4a6-7527-4341-8fbf-1a5403e07e2f\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"d49cd4a6-7527-4341-8fbf-1a5403e07e2f\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"d49cd4a6-7527-4341-8fbf-1a5403e07e2f\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import PandasDataFrameType, IntegerType, StringType, FloatType, DateType, Variant\n",
    "from snowflake.ml._internal.utils import identifier\n",
    "import backtesting as bt\n",
    "from backtesting.lib import crossover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bb551-87ec-4535-a8cf-8ae31d2e7c07",
   "metadata": {},
   "source": [
    "# 2.1 Reading Snowflake Connection Details, create a Session \n",
    "\n",
    "TODO: Update your json path for your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac1dc11-cc88-4c7a-a132-3c47fae6d8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Warehouse ASYNC_WH successfully created.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowflake_connection_cfg = json.loads(open(\"/home/harry/Development/Hol2.0-FS-Predictions/creds.json\").read()) # <--- Update here\n",
    "session = Session.builder.configs(snowflake_connection_cfg).create()\n",
    "session.sql(\"USE DATABASE HOL_DEMO\").collect()\n",
    "session.sql(\"CREATE OR REPLACE STAGE YOUR_STAGE\").collect()\n",
    "session.sql(\"CREATE OR REPLACE WAREHOUSE ASYNC_WH WITH WAREHOUSE_SIZE='MEDIUM' WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e332ec-6b04-4a53-b574-f8234091d4fd",
   "metadata": {},
   "source": [
    "# 2.2.1 Let's run a SPROC\n",
    "\n",
    "TODO: Just run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7676d6-e67e-476e-bf40-0ab01dbf146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"hello world\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hello_world(session: Session) -> Variant:\n",
    "    return \"hello world\"\n",
    "\n",
    "# Register sproc\n",
    "hello_world_demo = session.sproc.register(\n",
    "                              func=hello_world, \n",
    "                              name='hello_world', \n",
    "                              is_permanent=True, \n",
    "                              replace=True,\n",
    "                              stage_location='@HOL_DEMO.PUBLIC.YOUR_STAGE', \n",
    "                              packages=['snowflake-snowpark-python'])\n",
    "# Call sproc\n",
    "hello_world_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76de14-c780-4a9e-a3a2-82514007c7cd",
   "metadata": {},
   "source": [
    "# 2.2.2 Trying to Create a SPROC Using the python BACKTEST library\n",
    "\n",
    "TODO: Just run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ad7182-c5da-4389-a39e-b20766406b9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot add package backtesting because it is not available in Snowflake and Session.custom_package_usage_config['enabled'] is not set to True. To upload these packages, you can set it to True or find the directory of these packages and add it via Session.add_import. See details at https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs.html#using-third-party-packages-from-anaconda-in-a-udf.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt works!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Register sproc\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m sproc_test_backtesting_demo \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39msproc\u001b[38;5;241m.\u001b[39mregister(\n\u001b[1;32m      7\u001b[0m                               func\u001b[38;5;241m=\u001b[39msproc_test_backtesting, \n\u001b[1;32m      8\u001b[0m                               name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOUR_SPROC_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m                               is_permanent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     10\u001b[0m                               replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                               stage_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@YOUR_STAGE\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m                               packages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnowflake-snowpark-python\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbacktesting\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbokeh\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Call sproc\u001b[39;00m\n\u001b[1;32m     14\u001b[0m sproc_test_backtesting_demo()\n",
      "File \u001b[0;32m~/.conda/envs/snowpark-ml-hol/lib/python3.11/site-packages/snowflake/snowpark/stored_procedure.py:532\u001b[0m, in \u001b[0;36mStoredProcedureRegistration.register\u001b[0;34m(self, func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, parallel, execute_as, strict, external_access_integrations, secrets, statement_params, source_code_display, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m check_register_args(\n\u001b[1;32m    528\u001b[0m     TempObjectType\u001b[38;5;241m.\u001b[39mPROCEDURE, name, is_permanent, stage_location, parallel\n\u001b[1;32m    529\u001b[0m )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# register stored procedure\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_register_sp(\n\u001b[1;32m    533\u001b[0m     func,\n\u001b[1;32m    534\u001b[0m     return_type,\n\u001b[1;32m    535\u001b[0m     input_types,\n\u001b[1;32m    536\u001b[0m     name,\n\u001b[1;32m    537\u001b[0m     stage_location,\n\u001b[1;32m    538\u001b[0m     imports,\n\u001b[1;32m    539\u001b[0m     packages,\n\u001b[1;32m    540\u001b[0m     replace,\n\u001b[1;32m    541\u001b[0m     if_not_exists,\n\u001b[1;32m    542\u001b[0m     parallel,\n\u001b[1;32m    543\u001b[0m     strict,\n\u001b[1;32m    544\u001b[0m     external_access_integrations\u001b[38;5;241m=\u001b[39mexternal_access_integrations,\n\u001b[1;32m    545\u001b[0m     secrets\u001b[38;5;241m=\u001b[39msecrets,\n\u001b[1;32m    546\u001b[0m     statement_params\u001b[38;5;241m=\u001b[39mstatement_params,\n\u001b[1;32m    547\u001b[0m     execute_as\u001b[38;5;241m=\u001b[39mexecute_as,\n\u001b[1;32m    548\u001b[0m     api_call_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoredProcedureRegistration.register\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    549\u001b[0m     source_code_display\u001b[38;5;241m=\u001b[39msource_code_display,\n\u001b[1;32m    550\u001b[0m     anonymous\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manonymous\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    551\u001b[0m     is_permanent\u001b[38;5;241m=\u001b[39mis_permanent,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# force_inline_code avoids uploading python file\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m# when we know the code is not too large. This is useful\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# in Pandas API to create stored procedures not registered by users.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     force_inline_code\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_inline_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    556\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/snowpark-ml-hol/lib/python3.11/site-packages/snowflake/snowpark/stored_procedure.py:754\u001b[0m, in \u001b[0;36mStoredProcedureRegistration._do_register_sp\u001b[0;34m(self, func, return_type, input_types, sp_name, stage_location, imports, packages, replace, if_not_exists, parallel, strict, source_code_display, statement_params, execute_as, anonymous, api_call_source, skip_upload_on_content_match, is_permanent, external_access_integrations, secrets, force_inline_code)\u001b[0m\n\u001b[1;32m    742\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_types))]\n\u001b[1;32m    743\u001b[0m input_args \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    744\u001b[0m     UDFColumn(dt, arg_name) \u001b[38;5;28;01mfor\u001b[39;00m dt, arg_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_types, arg_names[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    745\u001b[0m ]\n\u001b[1;32m    747\u001b[0m (\n\u001b[1;32m    748\u001b[0m     handler,\n\u001b[1;32m    749\u001b[0m     code,\n\u001b[1;32m    750\u001b[0m     all_imports,\n\u001b[1;32m    751\u001b[0m     all_packages,\n\u001b[1;32m    752\u001b[0m     upload_file_stage_location,\n\u001b[1;32m    753\u001b[0m     custom_python_runtime_version_allowed,\n\u001b[0;32m--> 754\u001b[0m ) \u001b[38;5;241m=\u001b[39m resolve_imports_and_packages(\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session,\n\u001b[1;32m    756\u001b[0m     TempObjectType\u001b[38;5;241m.\u001b[39mPROCEDURE,\n\u001b[1;32m    757\u001b[0m     func,\n\u001b[1;32m    758\u001b[0m     arg_names,\n\u001b[1;32m    759\u001b[0m     udf_name,\n\u001b[1;32m    760\u001b[0m     stage_location,\n\u001b[1;32m    761\u001b[0m     imports,\n\u001b[1;32m    762\u001b[0m     packages,\n\u001b[1;32m    763\u001b[0m     parallel,\n\u001b[1;32m    764\u001b[0m     statement_params\u001b[38;5;241m=\u001b[39mstatement_params,\n\u001b[1;32m    765\u001b[0m     source_code_display\u001b[38;5;241m=\u001b[39msource_code_display,\n\u001b[1;32m    766\u001b[0m     skip_upload_on_content_match\u001b[38;5;241m=\u001b[39mskip_upload_on_content_match,\n\u001b[1;32m    767\u001b[0m     is_permanent\u001b[38;5;241m=\u001b[39mis_permanent,\n\u001b[1;32m    768\u001b[0m     force_inline_code\u001b[38;5;241m=\u001b[39mforce_inline_code,\n\u001b[1;32m    769\u001b[0m )\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m custom_python_runtime_version_allowed:\n\u001b[1;32m    772\u001b[0m     check_python_runtime_version(\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39m_runtime_version_from_requirement\n\u001b[1;32m    774\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/snowpark-ml-hol/lib/python3.11/site-packages/snowflake/snowpark/_internal/udf_utils.py:826\u001b[0m, in \u001b[0;36mresolve_imports_and_packages\u001b[0;34m(session, object_type, func, arg_names, udf_name, stage_location, imports, packages, parallel, is_pandas_udf, is_dataframe_input, max_batch_size, statement_params, source_code_display, skip_upload_on_content_match, is_permanent, force_inline_code)\u001b[0m\n\u001b[1;32m    820\u001b[0m upload_and_import_stage \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    821\u001b[0m     import_only_stage \u001b[38;5;28;01mif\u001b[39;00m is_permanent \u001b[38;5;28;01melse\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget_session_stage()\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# resolve packages\u001b[39;00m\n\u001b[1;32m    825\u001b[0m resolved_packages \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 826\u001b[0m     session\u001b[38;5;241m.\u001b[39m_resolve_packages(packages, include_pandas\u001b[38;5;241m=\u001b[39mis_pandas_udf)\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m packages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_resolve_packages(\n\u001b[1;32m    829\u001b[0m         [],\n\u001b[1;32m    830\u001b[0m         session\u001b[38;5;241m.\u001b[39m_packages,\n\u001b[1;32m    831\u001b[0m         validate_package\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    832\u001b[0m         include_pandas\u001b[38;5;241m=\u001b[39mis_pandas_udf,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m )\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# resolve imports\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imports:\n",
      "File \u001b[0;32m~/.conda/envs/snowpark-ml-hol/lib/python3.11/site-packages/snowflake/snowpark/session.py:1130\u001b[0m, in \u001b[0;36mSession._resolve_packages\u001b[0;34m(self, packages, existing_packages_dict, validate_package, include_pandas)\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot add package \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mversion_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because Anaconda terms must be accepted \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby ORGADMIN to use Anaconda 3rd party packages. Please follow the instructions at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1128\u001b[0m     )\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_package_usage_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot add package \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_req\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because it is not available in Snowflake \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand Session.custom_package_usage_config[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] is not set to True. To upload these packages, you can \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset it to True or find the directory of these packages and add it via Session.add_import. See details at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs.html#using-third-party-packages-from-anaconda-in-a-udf.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1135\u001b[0m     )\n\u001b[1;32m   1136\u001b[0m unsupported_packages\u001b[38;5;241m.\u001b[39mappend(package)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot add package backtesting because it is not available in Snowflake and Session.custom_package_usage_config['enabled'] is not set to True. To upload these packages, you can set it to True or find the directory of these packages and add it via Session.add_import. See details at https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs.html#using-third-party-packages-from-anaconda-in-a-udf."
     ]
    }
   ],
   "source": [
    "def sproc_test_backtesting(session: Session) -> Variant:\n",
    "    import backtesting as bt\n",
    "    return \"It works!\"\n",
    "\n",
    "# Register sproc\n",
    "sproc_test_backtesting_demo = session.sproc.register(\n",
    "                              func=sproc_test_backtesting, \n",
    "                              name='YOUR_SPROC_NAME', \n",
    "                              is_permanent=True, \n",
    "                              replace=True,\n",
    "                              stage_location='@YOUR_STAGE', \n",
    "                              packages=['snowflake-snowpark-python', 'backtesting', 'bokeh'])\n",
    "# Call sproc\n",
    "sproc_test_backtesting_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a2b8a-bf34-4ac3-8fb4-d89052ab6943",
   "metadata": {},
   "source": [
    "Disaster!  Apparently Backtesting isn't available in Snowflake's Anaconda Channel (YET), but not to worry, we have a fix\n",
    "\n",
    "See here for the full list of available packages https://repo.anaconda.com/pkgs/snowflake/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dffe77c-582e-4d75-8995-f81d5412b482",
   "metadata": {},
   "source": [
    "# 2.2.3 Trying to Create a SPROC Using the python BACKTEST library\n",
    "\n",
    "TODO: \n",
    "\n",
    "1. Open up your browswer and log in to Snowflake, copy 'wheel_loader.py' and 'Backtesting-0.3.4.dev30+g0ce24d8-py3-none-any.whl' to Your_Stage (Data-> DataBases -> HOL_DEMO -> PUBLIC -> STAGES)\n",
    "2. Run the cell\n",
    "\n",
    "Note you can do this programmatically with SNOWCLI, but this is an easy way for this demo.  Further reading - https://www.askpython.com/python/examples/wheel-for-python-package if you want to learn how to create a whl file from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1a337-5eab-46cf-8cd0-fb5bff46caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sproc to test that the import was successful\n",
    "def sproc_test_backtesting(session: Session) -> Variant:\n",
    "    import wheel_loader\n",
    "    wheel_loader.load('Backtesting-0.3.4.dev30+g0ce24d8-py3-none-any.whl')\n",
    "    import pandas as pd\n",
    "    import backtesting as bt\n",
    "    return \"It works!\"\n",
    "\n",
    "# Register sproc\n",
    "sproc_test_backtesting_demo = session.sproc.register(\n",
    "                              func=sproc_test_backtesting, \n",
    "                              name='YOUR_SPROC_NAME', \n",
    "                              is_permanent=True, \n",
    "                              replace=True,\n",
    "                              stage_location='@YOUR_STAGE', \n",
    "                              packages=['snowflake-snowpark-python', 'bokeh'], # Needed as dependency\n",
    "                              imports=[\"@YOUR_STAGE/wheel_loader.py\",\n",
    "                                       \"@YOUR_STAGE/Backtesting-0.3.4.dev30+g0ce24d8-py3-none-any.whl\"])\n",
    "# Call sproc\n",
    "sproc_test_backtesting_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e92d5-3437-45ae-b751-8235df4bcef9",
   "metadata": {},
   "source": [
    "# 2.2.4 Using the Backtest library locally\n",
    "\n",
    "TODO: Optional - update the Strategy as you see fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913097dd-86db-4fcd-9611-879f200aa5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Strategy\n",
    "def MovingAverage(closes:pd.Series, n:int) -> pd.Series:\n",
    "    return pd.Series(closes).rolling(n).mean()\n",
    "\n",
    "class SmaCross(bt.Strategy):\n",
    "    sma_fast = 12 \n",
    "    sma_slow = 35\n",
    "    \n",
    "    def init(self):\n",
    "        self.sma1 = self.I(MovingAverage, self.data.Close, self.sma_fast)\n",
    "        self.sma2 = self.I(MovingAverage, self.data.Close, self.sma_slow)\n",
    "\n",
    "    def next(self):\n",
    "        if not self.position and crossover(self.sma1, self.sma2) and crossover(self.data.CLOSE_PREDICT,self.sma2):\n",
    "            self.buy()\n",
    "        elif self.position and crossover(self.sma2, self.sma1):\n",
    "            self.position.close()\n",
    "\n",
    "# Run backtest\n",
    "data = session.sql(\"\"\"SELECT * FROM ML_PREDICT WHERE SYMBOL = 'IBM'\"\"\").to_pandas()\n",
    "data.columns = ['DATE', 'Open', 'High', 'Low', 'Close', 'SYMBOL', 'CLOSE_M1', 'CLOSE_M2', 'CLOSE_M3', 'CLOSE_M4', 'CLOSE_M5', 'CLOSE_PREDICT']\n",
    "btest = bt.Backtest(data, SmaCross, cash=10_000, commission=0,exclusive_orders=True)\n",
    "stats = btest.run()[:-3]\n",
    "df = pd.DataFrame(stats).T\n",
    "df['Strategy_Name'] = \"SMA_CROSS\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5604cd-5797-488b-aeba-f3080ea5328d",
   "metadata": {},
   "source": [
    "# 2.2.5 Putting it all together\n",
    "\n",
    "TODO: Update the SPROC with a Strategy\n",
    "\n",
    "hints: \n",
    "1. This should be a copy and paste exercise, don't over think it\n",
    "2. writing to a table from pandas looks like this session.write_pandas(df, table_name='BACKTEST_RESULTS', auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434933cb-e95e-488a-9e8d-595558c47006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sproc_test_backtesting(session: Session, symbol:str, target_table:str) -> Variant:\n",
    "    import wheel_loader\n",
    "    wheel_loader.load('Backtesting-0.3.4.dev30+g0ce24d8-py3-none-any.whl')\n",
    "\n",
    "\n",
    "    ### Do Part 1 here\n",
    "\n",
    "    ### Do Part 2 here\n",
    "\n",
    "# Register sproc\n",
    "sproc_test_backtesting_demo = session.sproc.register(\n",
    "                              func=sproc_test_backtesting, \n",
    "                              name='YOUR_SPROC_NAME', \n",
    "                              is_permanent=True, \n",
    "                              replace=True,\n",
    "                              stage_location='@YOUR_STAGE', \n",
    "                              packages=['snowflake-snowpark-python', 'bokeh'], # Needed as dependency\n",
    "                              imports=[\"@YOUR_STAGE/wheel_loader.py\",\n",
    "                                       \"@YOUR_STAGE/Backtesting-0.3.4.dev30+g0ce24d8-py3-none-any.whl\"])\n",
    "# Call sproc\n",
    "sproc_test_backtesting_demo(\"IBM\", \"SPROC_BT_TEST\")\n",
    "session.table('SPROC_BT_TEST').limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52907087-4363-49ce-85dc-991cd393779d",
   "metadata": {},
   "source": [
    "# 2.3 Parallelise with a UDTF\n",
    "\n",
    "TODO: \n",
    "\n",
    "1. Update the UDTF with code that mirrors the SPROC above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c541aad1-9c0f-4a3d-9e18-b75d787f6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'bokeh' in the local environment is 3.3.4, which does not fit the criteria for the requirement 'bokeh'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "class Strat_Backtest:\n",
    "    def end_partition(self, data):\n",
    "        data.columns = ['DATE', 'Open', 'High', 'Low', 'Close', 'SYMBOL', 'CLOSE_PREDICT']\n",
    "\n",
    "        ### Do Part 1 here\n",
    "\n",
    "        yield df_stats # note instead of writing to a table as you do in a stored procedure, in a UDTF you return a pandas dataframe (see the next line) which gets combined into a snowpark dataframe\n",
    "\n",
    "# Register UDTF\n",
    "Strat_Backtest.end_partition._sf_vectorized_input = pd.DataFrame\n",
    "strat_bt_udtf = session.udtf.register(\n",
    "    Strat_Backtest, # the class\n",
    "    input_types=[PandasDataFrameType([DateType(), FloatType(),FloatType(),FloatType(),FloatType(),StringType(), FloatType()])],\n",
    "    output_schema=PandasDataFrameType([FloatType()]*28+[StringType()],\n",
    "                                      [\"ST\", \"End_\", 'Duration', 'Exposure_Time_pct', 'Equity_Final_USD',\n",
    "                                       'Equity_Peak_USD', 'Return_pct', 'Buy_and_Hold_Return_pct',\n",
    "                                       'Return_Ann_pct', 'Volatility_Ann_pct', 'Sharpe_Ratio',\n",
    "                                       'Sortino_Ratio', 'Calmar_Ratio', 'Max_Drawdown_pct',\n",
    "                                       'Avg_Drawdown_pct', 'Max_Drawdown_Duration', 'Avg_Drawdown_Duration',\n",
    "                                       'Num_Trades', 'Win_Rate_pct', 'Best_Trade_pct', 'Worst_Trade_pct',\n",
    "                                       'Avg_Trade_pct', 'Max_Trade_Duration', 'Avg_Trade_Duration',\n",
    "                                       'Profit_Factor', 'Expectancy_pct', 'SQN', \"Kelly_Criterion\",\"STRAT\"]),\n",
    "                              stage_location='@YOUR_STAGE', \n",
    "                              packages=['snowflake-snowpark-python', 'bokeh'], # Needed as dependency\n",
    "                              imports=[\"@YOUR_STAGE/wheel_loader.py\",\n",
    "                                       \"@YOUR_STAGE/Backtesting-0.3.4.dev30+g0ce24d8-py3-none-any.whl\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772832a0-7ec7-4c70-952c-f3b2335f6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = session.table(\"ML_PREDICT\")\n",
    "sdf_prepped = sdf.select(strat_bt_udtf(*['DATE', 'Open', 'High', 'Low', 'Close', 'SYMBOL', 'CLOSE_PREDICT']).over(partition_by=['SYMBOL']))\n",
    "sdf_prepped.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73b54e9-1d17-486a-af93-b64a9b1fbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_prepped.write.save_as_table(\"UDTF_BT_TEST\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173de41f-1d61-4255-8075-0143675765e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
